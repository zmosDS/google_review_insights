{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad90a916-375c-4b47-a32d-49585abefdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-22 22:13:49.201353: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-02-22 22:13:49.201396: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-02-22 22:13:49.202855: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-02-22 22:13:49.214197: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "from datasets import Dataset, load_from_disk\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, classification_report, f1_score\n",
    "import random \n",
    "import warnings\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958ccb77-f758-4949-88c0-52e9894db9a7",
   "metadata": {},
   "source": [
    "### Load tokenized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f11b3e6b-b363-472e-bcc6-7a9ef987aa07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4767aa3554f4890931d318fa9b7c96f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 22,614,379 rows\n"
     ]
    }
   ],
   "source": [
    "# Dataset stays on disk, rows load only when needed\n",
    "tokenized_dataset = load_from_disk('tokenized_for_roberta')\n",
    "print(f\"Loaded {len(tokenized_dataset):,} rows\")\n",
    "\n",
    "aspect_cols = [\n",
    "             'product_quality_positive', 'product_quality_negative',\n",
    "             'service_positive', 'service_negative',\n",
    "             'wait_time_positive', 'wait_time_negative',\n",
    "             'price_value_positive', 'price_value_negative',\n",
    "             'cleanliness_positive', 'cleanliness_negative',\n",
    "             'atmosphere_positive', 'atmosphere_negative',\n",
    "             'general_positive', 'general_negative'\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132151a2-e61e-41ac-b137-5433270a5aaa",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c355f269-e439-4e72-a742-75ae69efded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "def compute_metrics(pred):\n",
    "    \"\"\"Compute evaluation metrics for multi-label classification.\"\"\"\n",
    "    labels = pred.label_ids\n",
    "    preds = (pred.predictions > 0.5).astype(int)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average='weighted', zero_division=0\n",
    "    )\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee175d2e-4aad-42df-b506-a461253ebdb4",
   "metadata": {},
   "source": [
    "# RoBERTa-base (100k Sample + 2x Neg)\n",
    "\n",
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd4abd5f-ad88-4021-a9f7-739076c0d8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train subset: 90,000\n",
      "Test subset:  10,000\n",
      "Loading RoBERTa model...\n",
      "Model loaded with 14 output labels\n",
      "\n",
      "Starting training...\n",
      "\n",
      "{'loss': 0.1499, 'grad_norm': 0.30931419134140015, 'learning_rate': 1.3333333333333333e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 0.08908729255199432, 'eval_accuracy': 0.8933, 'eval_f1': 0.916970687272749, 'eval_precision': 0.9256621110101607, 'eval_recall': 0.9133381478806732, 'eval_runtime': 54.1186, 'eval_samples_per_second': 184.779, 'eval_steps_per_second': 1.46, 'epoch': 1.0}\n",
      "{'loss': 0.0749, 'grad_norm': 1.9435322284698486, 'learning_rate': 6.666666666666667e-06, 'epoch': 2.0}\n",
      "{'eval_loss': 0.07328711450099945, 'eval_accuracy': 0.9101, 'eval_f1': 0.927333552744421, 'eval_precision': 0.930464043541008, 'eval_recall': 0.9244486417421255, 'eval_runtime': 54.2656, 'eval_samples_per_second': 184.279, 'eval_steps_per_second': 1.456, 'epoch': 2.0}\n",
      "{'loss': 0.0605, 'grad_norm': 2.247819423675537, 'learning_rate': 0.0, 'epoch': 3.0}\n",
      "{'eval_loss': 0.07081868499517441, 'eval_accuracy': 0.9153, 'eval_f1': 0.9288570706841401, 'eval_precision': 0.9345999069748724, 'eval_recall': 0.9237820121104383, 'eval_runtime': 54.3395, 'eval_samples_per_second': 184.028, 'eval_steps_per_second': 1.454, 'epoch': 3.0}\n",
      "{'train_runtime': 5049.2064, 'train_samples_per_second': 53.474, 'train_steps_per_second': 0.836, 'train_loss': 0.0951012631949303, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4221, training_loss=0.0951012631949303, metrics={'train_runtime': 5049.2064, 'train_samples_per_second': 53.474, 'train_steps_per_second': 0.836, 'train_loss': 0.0951012631949303, 'epoch': 3.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration for each run\n",
    "SAMPLE_SIZE   = 100_000\n",
    "TEST_SIZE     = 0.1\n",
    "EPOCHS        = 3\n",
    "TRAIN_BATCH   = 64\n",
    "EVAL_BATCH    = 128\n",
    "LEARNING_RATE = 2e-5\n",
    "SEED          = 2\n",
    "\n",
    "# Apply class weights: 2x penalty on negative labels (odd indices)\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss = nn.BCEWithLogitsLoss(pos_weight=weights)(logits, labels.float())\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "NEG_WEIGHT = 2.0\n",
    "weights = torch.ones(len(aspect_cols))\n",
    "weights[1::2] = NEG_WEIGHT  # every other label starting at index 1 is negative\n",
    "weights = weights.to(device)\n",
    "\n",
    "# Sample & Split\n",
    "random.seed(SEED)\n",
    "sample       = tokenized_dataset.select(random.sample(range(len(tokenized_dataset)), SAMPLE_SIZE))\n",
    "split        = sample.train_test_split(test_size=TEST_SIZE, seed=SEED)\n",
    "train_subset = split['train']\n",
    "test_subset  = split['test']\n",
    "\n",
    "print(f\"Train subset: {len(train_subset):,}\")\n",
    "print(f\"Test subset:  {len(test_subset):,}\")\n",
    "\n",
    "# Load RoBERTa-base Model \n",
    "print(\"Loading RoBERTa model...\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    num_labels=len(aspect_cols),\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "print(f\"Model loaded with {len(aspect_cols)} output labels\\n\")\n",
    "\n",
    "# Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'./results_roberta_{SAMPLE_SIZE}',\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=TRAIN_BATCH,\n",
    "    per_device_eval_batch_size=EVAL_BATCH,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    dataloader_pin_memory=torch.cuda.is_available(),\n",
    "    dataloader_num_workers=16,\n",
    "    optim=\"adamw_torch_fused\",\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_subset,\n",
    "    eval_dataset=test_subset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "print(\"Starting training...\\n\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458b1003-de5c-4455-b547-9ecfc4724cff",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25c980ab-d170-45b3-98f4-52c6f85a7f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RoBERTa (100,000 Sample + 2x Penalty)\n",
      "{'eval_loss': 0.05093773454427719, 'eval_accuracy': 0.9372111111111111, 'eval_f1': 0.9541620808327217, 'eval_precision': 0.9601165676547125, 'eval_recall': 0.9485402990967869, 'eval_runtime': 482.0834, 'eval_samples_per_second': 186.69, 'eval_steps_per_second': 1.46, 'epoch': 3.0}\n",
      "Training Accuracy: 0.9372\n",
      "{'eval_loss': 0.07081868499517441, 'eval_accuracy': 0.9153, 'eval_f1': 0.9288570706841401, 'eval_precision': 0.9345999069748724, 'eval_recall': 0.9237820121104383, 'eval_runtime': 54.254, 'eval_samples_per_second': 184.318, 'eval_steps_per_second': 1.456, 'epoch': 3.0}\n",
      "Test Accuracy:     0.9153\n",
      "\n",
      "F1 Score (macro):    0.8794\n",
      "F1 Score (weighted): 0.9289\n",
      "\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "product_quality_positive       0.96      0.96      0.96      3117\n",
      "product_quality_negative       0.85      0.81      0.83       771\n",
      "        service_positive       0.96      0.97      0.96      2416\n",
      "        service_negative       0.89      0.84      0.87       677\n",
      "      wait_time_positive       0.94      0.90      0.92      1236\n",
      "      wait_time_negative       0.86      0.80      0.83       444\n",
      "    price_value_positive       0.93      0.93      0.93      1106\n",
      "    price_value_negative       0.82      0.75      0.78       366\n",
      "    cleanliness_positive       0.95      0.93      0.94       522\n",
      "    cleanliness_negative       0.81      0.82      0.82       168\n",
      "     atmosphere_positive       0.94      0.94      0.94       805\n",
      "     atmosphere_negative       0.84      0.77      0.80       201\n",
      "        general_positive       0.96      0.97      0.97      5422\n",
      "        general_negative       0.82      0.71      0.76       750\n",
      "\n",
      "               micro avg       0.94      0.92      0.93     18001\n",
      "               macro avg       0.90      0.86      0.88     18001\n",
      "            weighted avg       0.93      0.92      0.93     18001\n",
      "             samples avg       0.79      0.78      0.79     18001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(test_subset)\n",
    "y_pred = (predictions.predictions > 0.5).astype(int)\n",
    "y_true = predictions.label_ids\n",
    "\n",
    "print(f\"\\nRoBERTa ({SAMPLE_SIZE:,} Sample + 2x Penalty)\")\n",
    "print(f\"Training Accuracy: {trainer.evaluate(train_subset)['eval_accuracy']:.4f}\")\n",
    "print(f\"Test Accuracy:     {trainer.evaluate(test_subset)['eval_accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\nF1 Score (macro):    {f1_score(y_true, y_pred, average='macro', zero_division=0):.4f}\")\n",
    "print(f\"F1 Score (weighted): {f1_score(y_true, y_pred, average='weighted', zero_division=0):.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=aspect_cols, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cee1005-f48d-4d63-a500-335b411f99ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory\n",
    "del model\n",
    "del trainer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() if torch.cuda.is_available() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218d0e72-73ed-484d-bbf4-9904d09536b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
