{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa4eef34-e15d-401d-89c5-3b7552ff7c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "310ee1ac-6513-4bf7-b3c3-7e734279b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "paths = {\n",
    "    'cleaned_model_fulltxt': \"../data/cleaned_for_modeling_fulltxt.csv\",\n",
    "    'cleaned_model_sentences': \"../data/cleaned_for_modeling_sentences.csv\",\n",
    "    'cleaned_for_tfidf': \"../data/cleaned_for_tfidf.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44dd909-9b2e-4d0a-a833-8b0615f5741b",
   "metadata": {},
   "source": [
    "# Read in cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0776e9-7301-4701-9ce7-3f78aff4f076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV\n",
    "df = pd.read_csv('../data/cleaned_for_modeling.csv')\n",
    "print(f\"Loaded {len(df):,} rows\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cc2391-2228-4578-8fce-a56e21c3da49",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab077c4-3bdf-48bd-ae97-c8c6662c635f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define functions\n",
    "\n",
    "def is_likely_english(text):\n",
    "    \"\"\"Fast heuristic: >80% ASCII characters = likely English.\"\"\"\n",
    "    if pd.isna(text) or len(str(text).strip()) == 0:\n",
    "        return False\n",
    "    text = str(text)\n",
    "    ascii_count = sum(1 for c in text if ord(c) < 128)\n",
    "    return (ascii_count / len(text)) > 0.8\n",
    "\n",
    "def filter_english_only(df):\n",
    "    \"\"\"Filter to English-only reviews.\"\"\"\n",
    "    print(f\"Before English filter: {len(df):,} rows\")\n",
    "    df_clean = df.copy()\n",
    "    df_clean['is_english'] = df_clean['text'].apply(is_likely_english)\n",
    "    df_clean = df_clean[df_clean['is_english']].drop(columns=['is_english'])\n",
    "    print(f\"  After: {len(df_clean):,} rows ({len(df) - len(df_clean):,} removed)\\n\")\n",
    "    return df_clean\n",
    "\n",
    "def filter_original_tag(df):\n",
    "    \"\"\"Remove reviews with Google's (Original) translation tag.\"\"\"\n",
    "    print(f\"Before (Original) tag filter: {len(df):,} rows\")\n",
    "    df_clean = df[~df['text'].str.contains(r'\\(Original\\)', na=False)].copy()\n",
    "    print(f\"  After: {len(df_clean):,} rows ({len(df) - len(df_clean):,} removed)\\n\")\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684d426d-4112-4c12-ae80-1d6db2956125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply english filtering pipeline\n",
    "\n",
    "df = (df\n",
    "    .pipe(filter_english_only)\n",
    "    .pipe(filter_original_tag)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f\"Final dataset: {len(df):,} rows\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fd005c-6cbc-42f3-9859-2564685d69f1",
   "metadata": {},
   "source": [
    "# Add review_id (unique per review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc95e6c-63a1-48e7-b6ce-5ef977f2df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define review_id generating function\n",
    "def make_review_id(df):\n",
    "\n",
    "    # Combine fields into one string\n",
    "    combined = (\n",
    "        df[\"user_id\"].astype(str) + \"||\" +\n",
    "        df[\"gmap_id\"].astype(str) + \"||\" +\n",
    "        df[\"rating\"].astype(str) + \"||\" +\n",
    "        df[\"text\"].astype(str)\n",
    "    )\n",
    "\n",
    "    # Create SHA256 hash and insert as first column\n",
    "    df.insert(\n",
    "        0,\n",
    "        \"review_id\",\n",
    "        combined.apply(lambda x: hashlib.sha256(x.encode(\"utf-8\")).hexdigest())\n",
    "    )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc273a2-4f7f-46ee-b69e-39e6ae8fe12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to dataframe\n",
    "df = (\n",
    "    df\n",
    "    .pipe(make_review_id)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1768aa-25b6-4c2f-892b-97c50e607005",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4959dd-5c7b-4ab1-8f71-2f7409fb86d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates (found 5 when exploring the data)\n",
    "before = len(df)\n",
    "df = df.drop_duplicates(subset=\"review_id\", keep=\"first\")\n",
    "after = len(df)\n",
    "\n",
    "print(f\"Rows before deduplication: {before:,}\")\n",
    "print(f\"Rows after deduplication:  {after:,}\")\n",
    "print(f\"Duplicates removed:        {before - after:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419f3c4a-1916-42e5-8879-3f4c2b144c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "df.to_csv(paths['cleaned_model_fulltxt'], index=False)\n",
    "print(f\"Saved to {paths['cleaned_model_fulltxt']}\\n\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a6daa7-1171-44a0-85da-d2eb93a85ac4",
   "metadata": {},
   "source": [
    "# For Baseline Model\n",
    "Logistic regression or Naive Bayes + TF-IDF\n",
    "* Lowercasing\n",
    "* Remove punctuation\n",
    "* Remove stop words, except for negations like not/no (in model pipeline)\n",
    "* N-grams (bigrams) (in model pipeline)\n",
    "* Lemmatization (maybe)\n",
    "* Sentence-level tokens (maybe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8fe614-9c7f-4d18-92a1-2fbb38419af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_text_chunked_csv(in_path: str, out_path: str, chunksize: int, text_col: str, new_col: str):\n",
    "    \"\"\"\n",
    "    Memory-safe baseline text processing\n",
    "    Reads `in_path` in chunks, creates `new_col` by:\n",
    "      - lowercasing\n",
    "      - removing punctuation (keeping letters/numbers/spaces)\n",
    "      - normalizing whitespace\n",
    "      - stripping leading/trailing spaces\n",
    "\n",
    "    Writes the result incrementally to `out_path`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_path : str\n",
    "        Input CSV path (e.g., \"reviews_with_review_id.csv\")\n",
    "    out_path : str\n",
    "        Output CSV path (e.g., \"reviews_with_text_classical.csv\")\n",
    "    chunksize : int\n",
    "        Number of rows per chunk. Lower if you still crash (e.g., 20_000).\n",
    "    text_col : str\n",
    "        Name of the raw text column in the input CSV.\n",
    "    new_col : str\n",
    "        Name of the output processed text column.\n",
    "    \"\"\"\n",
    "    first = True\n",
    "\n",
    "    # Use keep_default_na=False so empty strings don't become NaN unexpectedly\n",
    "    reader = pd.read_csv(in_path, chunksize=chunksize, keep_default_na=False)\n",
    "\n",
    "    for i, chunk in enumerate(reader, start=1):\n",
    "        if text_col not in chunk.columns:\n",
    "            raise KeyError(\n",
    "                f\"Column '{text_col}' not found. Available columns: {list(chunk.columns)}\"\n",
    "            )\n",
    "\n",
    "        s = chunk[text_col].astype(\"string\")\n",
    "\n",
    "        chunk[new_col] = (\n",
    "            s.str.lower()\n",
    "             .str.replace(r\"[^a-z0-9\\s]\", \" \", regex=True)\n",
    "             .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "             .str.strip()\n",
    "        )\n",
    "\n",
    "        # Write chunk to output CSV (append after first chunk)\n",
    "        chunk.to_csv(out_path, mode=\"w\" if first else \"a\", index=False, header=first)\n",
    "        first = False\n",
    "\n",
    "        # Lightweight progress\n",
    "        print(f\"âœ… Processed chunk {i:,} (rows: {len(chunk):,})\")\n",
    "\n",
    "    print(f\"ðŸŽ‰ Done. Wrote cleaned CSV to: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81bf310-b63b-4bdc-8ab0-33d0aa8d70d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_text_chunked_csv(\n",
    "    in_path=paths[\"cleaned_model_fulltxt\"],\n",
    "    out_path=paths[\"cleaned_for_tfidf\"],\n",
    "    chunksize=500_000,\n",
    "    text_col=\"text\",\n",
    "    new_col=\"text_baseline\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd4347cc-af39-45e3-9ccc-c58f2c074242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>text_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>456e420929727f933dbaed63eff45cde53c7b92438cf0d...</td>\n",
       "      <td>5</td>\n",
       "      <td>easy process extremely friendly helpful staff ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ea2ad448a8b443c1c42c5d4ca9dd84d02fe9f2f110b993...</td>\n",
       "      <td>5</td>\n",
       "      <td>my girlfriends and i took a weekend ski trip t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77efbe6a6f4d27512b59bb2f878b0ac8b533aa03a11fb7...</td>\n",
       "      <td>5</td>\n",
       "      <td>the team at black tie never disappoints our se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ba742a26b57396fde7a05136bbbf551906f5c6d9e66008...</td>\n",
       "      <td>5</td>\n",
       "      <td>they were awesome people first timer they help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57787d7d11fc5e75d7a7643fd966534de03fdc72cf764f...</td>\n",
       "      <td>5</td>\n",
       "      <td>great service fast responsive they came and pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6cd920c382945084ed2537452eef5d2603e3c19e4c26d6...</td>\n",
       "      <td>5</td>\n",
       "      <td>awesome incredible customer service profession...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>275023c6626a913042ec003365906cbf377ca45cfc0acf...</td>\n",
       "      <td>5</td>\n",
       "      <td>unforgettable remarkable customer for life i j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1bc8c890f35919ec310e65b64701a07a249989f0adcdd3...</td>\n",
       "      <td>5</td>\n",
       "      <td>good service affordable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>56a745e1bb00e7475f21f1fdd5051b5d328c54c74747ef...</td>\n",
       "      <td>5</td>\n",
       "      <td>nice people good service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32d6a0dcb40c36f484a2dfc47b50ae9b6eb86b0cc143dd...</td>\n",
       "      <td>5</td>\n",
       "      <td>awesome</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           review_id  rating  \\\n",
       "0  456e420929727f933dbaed63eff45cde53c7b92438cf0d...       5   \n",
       "1  ea2ad448a8b443c1c42c5d4ca9dd84d02fe9f2f110b993...       5   \n",
       "2  77efbe6a6f4d27512b59bb2f878b0ac8b533aa03a11fb7...       5   \n",
       "3  ba742a26b57396fde7a05136bbbf551906f5c6d9e66008...       5   \n",
       "4  57787d7d11fc5e75d7a7643fd966534de03fdc72cf764f...       5   \n",
       "5  6cd920c382945084ed2537452eef5d2603e3c19e4c26d6...       5   \n",
       "6  275023c6626a913042ec003365906cbf377ca45cfc0acf...       5   \n",
       "7  1bc8c890f35919ec310e65b64701a07a249989f0adcdd3...       5   \n",
       "8  56a745e1bb00e7475f21f1fdd5051b5d328c54c74747ef...       5   \n",
       "9  32d6a0dcb40c36f484a2dfc47b50ae9b6eb86b0cc143dd...       5   \n",
       "\n",
       "                                       text_baseline  \n",
       "0  easy process extremely friendly helpful staff ...  \n",
       "1  my girlfriends and i took a weekend ski trip t...  \n",
       "2  the team at black tie never disappoints our se...  \n",
       "3  they were awesome people first timer they help...  \n",
       "4  great service fast responsive they came and pi...  \n",
       "5  awesome incredible customer service profession...  \n",
       "6  unforgettable remarkable customer for life i j...  \n",
       "7                            good service affordable  \n",
       "8                           nice people good service  \n",
       "9                                            awesome  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CSV\n",
    "df = pd.read_csv(\n",
    "    paths[\"cleaned_for_tfidf\"],\n",
    "    usecols=[\"review_id\", \"rating\", \"text_baseline\"],\n",
    "    dtype={\n",
    "        \"review_id\": \"string\",\n",
    "        \"rating\": \"int8\",\n",
    "        \"text_baseline\": \"string\"\n",
    "    }\n",
    ")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f957b25e-de7e-4128-8446-b9f922db4411",
   "metadata": {},
   "source": [
    "# For Primary Model\n",
    "Transformer-based embeddings (e.g., distilBERT) + simple classifier (e.g., logistic regression)\n",
    "* Sentence-level tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37320b0d-95f4-4b55-8b66-ad7b7d7b135b",
   "metadata": {},
   "source": [
    "# For Advanced Model\n",
    "Large Language Model-based ABSA using prompting\n",
    "* None, wants raw text, capitalization, punctuation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f0aaef-c17c-41c7-9d8b-25431513d005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
