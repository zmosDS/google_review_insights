{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad90a916-375c-4b47-a32d-49585abefdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, classification_report, f1_score\n",
    "import random \n",
    "import warnings\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a25d24-ee9e-497a-b78e-beaa0b3ed860",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83ede892-90bd-405d-8101-a45391113f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b281f6184bd4881bfb8f0781c157d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 22,624,379 rows\n"
     ]
    }
   ],
   "source": [
    "# HuggingFace dataset\n",
    "dataset = Dataset.from_csv('../data/cleaned_for_LLM.csv')\n",
    "print(f\"Loaded {len(dataset):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b6732b-a1eb-4a44-a636-0cd3a21c0613",
   "metadata": {},
   "source": [
    "## RoBERTa Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46134290-f251-4adf-b53b-517f18534586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a9d63b0b65441ba0f7b11fdc9f0a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2262438 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dde6a43f4e044f5a71553bd64e6691e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/33 shards):   0%|          | 0/20361941 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044b212e1b744386815a392fcbca3b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/4 shards):   0%|          | 0/2262438 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 20,361,941 samples\n",
      "Test dataset:  2,262,438 samples\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "aspect_cols = [\n",
    "    'food_quality_positive', 'food_quality_negative', 'food_quality_neutral',\n",
    "    'service_positive', 'service_negative', 'service_neutral',\n",
    "    'wait_time_positive', 'wait_time_negative', 'wait_time_neutral',\n",
    "    'price_value_positive', 'price_value_negative', 'price_value_neutral',\n",
    "    'cleanliness_positive', 'cleanliness_negative', 'cleanliness_neutral',\n",
    "    'atmosphere_positive', 'atmosphere_negative', 'atmosphere_neutral'\n",
    "]\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    \"\"\"Tokenize text and prepare multi-label targets.\"\"\"\n",
    "    tokenized = tokenizer(\n",
    "        examples['text'],\n",
    "        padding='longest',  # only pads longest batch, not always full 128\n",
    "        truncation=True,\n",
    "        max_length=128     \n",
    "    )\n",
    "    labels = []\n",
    "    for i in range(len(examples['text'])):\n",
    "        label_row = [float(examples[col][i]) for col in aspect_cols]\n",
    "        labels.append(label_row)\n",
    "    tokenized['labels'] = labels\n",
    "    return tokenized\n",
    "\n",
    "# Split\n",
    "split = dataset.train_test_split(test_size=0.1, seed=2)\n",
    "\n",
    "# Tokenize\n",
    "print(\"Tokenizing datasets...\")\n",
    "train_dataset = split['train'].map(tokenize_function, batched=True, remove_columns=split['train'].column_names)\n",
    "test_dataset = split['test'].map(tokenize_function, batched=True, remove_columns=split['test'].column_names)\n",
    "\n",
    "# Save\n",
    "print(\"Saving datasets...\")\n",
    "train_dataset.save_to_disk('../data/bert_train_tokenized')\n",
    "test_dataset.save_to_disk('../data/bert_test_tokenized')\n",
    "\n",
    "print(f\"Train dataset: {len(train_dataset):,} samples\")\n",
    "print(f\"Test dataset:  {len(test_dataset):,} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05e0192-7a08-48a0-8d2e-cb7a87bb23e4",
   "metadata": {},
   "source": [
    "***Note:*** 0% is a display bug in the notebook/library version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5303d889-4810-4c3a-885b-085f342f00c1",
   "metadata": {},
   "source": [
    "### Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbf22bbd-59ee-470a-8cf8-30040e6234b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train subset: 22,500\n",
      "Test subset:  2,500\n"
     ]
    }
   ],
   "source": [
    "train_indices = random.sample(range(len(train_dataset)), 22500)\n",
    "train_subset = train_dataset.select(train_indices)\n",
    "\n",
    "test_indices = random.sample(range(len(test_dataset)), 2500)\n",
    "test_subset = test_dataset.select(test_indices)\n",
    "\n",
    "print(f\"Train subset: {len(train_subset):,}\")\n",
    "print(f\"Test subset:  {len(test_subset):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132151a2-e61e-41ac-b137-5433270a5aaa",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c355f269-e439-4e72-a742-75ae69efded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "def compute_metrics(pred):\n",
    "    \"\"\"Compute evaluation metrics for multi-label classification.\"\"\"\n",
    "    labels = pred.label_ids\n",
    "    preds = (pred.predictions > 0.5).astype(int)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average='weighted', zero_division=0\n",
    "    )\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a89408-9d03-4e01-98bb-c5ed8545e353",
   "metadata": {},
   "source": [
    "## RoBERTa-base (25k Sample)\n",
    "\n",
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3601f586-3001-4f6a-a204-3d0a85b31d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RoBERTa model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323908eced8f4771a6b6f33bdae05181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/197 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRobertaForSequenceClassification LOAD REPORT\u001b[0m from: roberta-base\n",
      "Key                             | Status     | \n",
      "--------------------------------+------------+-\n",
      "roberta.embeddings.position_ids | UNEXPECTED | \n",
      "lm_head.layer_norm.bias         | UNEXPECTED | \n",
      "lm_head.bias                    | UNEXPECTED | \n",
      "lm_head.dense.weight            | UNEXPECTED | \n",
      "lm_head.layer_norm.weight       | UNEXPECTED | \n",
      "lm_head.dense.bias              | UNEXPECTED | \n",
      "classifier.dense.bias           | MISSING    | \n",
      "classifier.out_proj.bias        | MISSING    | \n",
      "classifier.dense.weight         | MISSING    | \n",
      "classifier.out_proj.weight      | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded with 18 output labels\n",
      "\n",
      "Starting training...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2112' max='2112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2112/2112 1:47:32, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.060443</td>\n",
       "      <td>0.057929</td>\n",
       "      <td>0.835200</td>\n",
       "      <td>0.782257</td>\n",
       "      <td>0.814565</td>\n",
       "      <td>0.783551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.046927</td>\n",
       "      <td>0.045346</td>\n",
       "      <td>0.857200</td>\n",
       "      <td>0.836677</td>\n",
       "      <td>0.887658</td>\n",
       "      <td>0.821060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.037241</td>\n",
       "      <td>0.045397</td>\n",
       "      <td>0.867200</td>\n",
       "      <td>0.844941</td>\n",
       "      <td>0.877104</td>\n",
       "      <td>0.832072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f8fee1da9834d668ebacf1b8fb3590d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4820cf4bfe74a25865aff3a89468d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d0b86ea7e546c2ac5fc301f4cca697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['roberta.embeddings.LayerNorm.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias'].\n",
      "There were unexpected keys in the checkpoint model loaded: ['roberta.embeddings.LayerNorm.beta', 'roberta.embeddings.LayerNorm.gamma', 'roberta.encoder.layer.0.attention.output.LayerNorm.beta', 'roberta.encoder.layer.0.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.0.output.LayerNorm.beta', 'roberta.encoder.layer.0.output.LayerNorm.gamma', 'roberta.encoder.layer.1.attention.output.LayerNorm.beta', 'roberta.encoder.layer.1.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.1.output.LayerNorm.beta', 'roberta.encoder.layer.1.output.LayerNorm.gamma', 'roberta.encoder.layer.2.attention.output.LayerNorm.beta', 'roberta.encoder.layer.2.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.2.output.LayerNorm.beta', 'roberta.encoder.layer.2.output.LayerNorm.gamma', 'roberta.encoder.layer.3.attention.output.LayerNorm.beta', 'roberta.encoder.layer.3.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.3.output.LayerNorm.beta', 'roberta.encoder.layer.3.output.LayerNorm.gamma', 'roberta.encoder.layer.4.attention.output.LayerNorm.beta', 'roberta.encoder.layer.4.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.4.output.LayerNorm.beta', 'roberta.encoder.layer.4.output.LayerNorm.gamma', 'roberta.encoder.layer.5.attention.output.LayerNorm.beta', 'roberta.encoder.layer.5.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.5.output.LayerNorm.beta', 'roberta.encoder.layer.5.output.LayerNorm.gamma', 'roberta.encoder.layer.6.attention.output.LayerNorm.beta', 'roberta.encoder.layer.6.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.6.output.LayerNorm.beta', 'roberta.encoder.layer.6.output.LayerNorm.gamma', 'roberta.encoder.layer.7.attention.output.LayerNorm.beta', 'roberta.encoder.layer.7.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.7.output.LayerNorm.beta', 'roberta.encoder.layer.7.output.LayerNorm.gamma', 'roberta.encoder.layer.8.attention.output.LayerNorm.beta', 'roberta.encoder.layer.8.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.8.output.LayerNorm.beta', 'roberta.encoder.layer.8.output.LayerNorm.gamma', 'roberta.encoder.layer.9.attention.output.LayerNorm.beta', 'roberta.encoder.layer.9.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.9.output.LayerNorm.beta', 'roberta.encoder.layer.9.output.LayerNorm.gamma', 'roberta.encoder.layer.10.attention.output.LayerNorm.beta', 'roberta.encoder.layer.10.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.10.output.LayerNorm.beta', 'roberta.encoder.layer.10.output.LayerNorm.gamma', 'roberta.encoder.layer.11.attention.output.LayerNorm.beta', 'roberta.encoder.layer.11.attention.output.LayerNorm.gamma', 'roberta.encoder.layer.11.output.LayerNorm.beta', 'roberta.encoder.layer.11.output.LayerNorm.gamma'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2112, training_loss=0.06492481406100771, metrics={'train_runtime': 6456.9252, 'train_samples_per_second': 10.454, 'train_steps_per_second': 0.327, 'total_flos': 1.776254759424e+16, 'train_loss': 0.06492481406100771, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading RoBERTa model...\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    \"roberta-base\",\n",
    "    num_labels=len(label_cols),\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "print(f\"Model loaded with {len(label_cols)} output labels\\n\")\n",
    "\n",
    "# Training configuration\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results_distilbert',           # Directory to save model checkpoints\n",
    "    eval_strategy=\"epoch\",                       # Default: \"no\" | Evaluate at end of each epoch\n",
    "    save_strategy=\"epoch\",                       # Default: \"steps\" | Save checkpoint at end of each epoch\n",
    "    load_best_model_at_end=True,                 # Default: False | Load best checkpoint after training\n",
    "    metric_for_best_model='f1',                  # Default: \"loss\" | Use F1 score to determine best model\n",
    "    logging_steps=100,                           # Default: 500 | Log metrics every 100 steps\n",
    "    per_device_train_batch_size=32,              # Default: 8 | Batch size for training (reduce for limited hardware)\n",
    "    per_device_eval_batch_size=64,               # Default: 8 | Batch size for evaluation\n",
    "    dataloader_num_workers=4,                    # Default: 0 | Parallel data loading (reduce for limited hardware)\n",
    "    num_train_epochs=3,                          # Default: 3 | Number of training epochs\n",
    "    dataloader_pin_memory=False,                 # Suppress MPS  warning\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_subset,\n",
    "    eval_dataset=test_subset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"Starting training...\\n\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc478424-805a-4a9f-a5b8-039be7d11326",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "496d73ca-cebc-4c2e-8e65-7750dd0b716b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa (25,000 Sample):\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='392' max='352' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [352/352 09:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9095\n",
      "Test Accuracy:     0.8672\n",
      "\n",
      "F1 Score (macro):    0.5889\n",
      "F1 Score (weighted): 0.8449\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       723\n",
      "           1       0.72      0.64      0.68        80\n",
      "           2       0.46      0.14      0.21        88\n",
      "           3       0.96      0.95      0.96       607\n",
      "           4       0.84      0.84      0.84       110\n",
      "           5       0.53      0.16      0.25        50\n",
      "           6       0.92      0.90      0.91       327\n",
      "           7       0.83      0.75      0.79        76\n",
      "           8       0.50      0.10      0.17        50\n",
      "           9       0.92      0.95      0.93       260\n",
      "          10       0.86      0.62      0.72        61\n",
      "          11       0.20      0.02      0.04        44\n",
      "          12       0.96      0.94      0.95       132\n",
      "          13       0.89      0.70      0.78        23\n",
      "          14       0.00      0.00      0.00        16\n",
      "          15       0.95      0.95      0.95       213\n",
      "          16       0.75      0.29      0.41        21\n",
      "          17       0.20      0.04      0.07        25\n",
      "\n",
      "   micro avg       0.92      0.83      0.87      2906\n",
      "   macro avg       0.69      0.55      0.59      2906\n",
      "weighted avg       0.88      0.83      0.84      2906\n",
      " samples avg       0.56      0.55      0.55      2906\n",
      "\n",
      "\n",
      "\n",
      "Label Index Key:\n",
      "  0: food_quality_positive\n",
      "  1: food_quality_negative\n",
      "  2: food_quality_neutral\n",
      "  3: service_positive\n",
      "  4: service_negative\n",
      "  5: service_neutral\n",
      "  6: wait_time_positive\n",
      "  7: wait_time_negative\n",
      "  8: wait_time_neutral\n",
      "  9: price_value_positive\n",
      "  10: price_value_negative\n",
      "  11: price_value_neutral\n",
      "  12: cleanliness_positive\n",
      "  13: cleanliness_negative\n",
      "  14: cleanliness_neutral\n",
      "  15: atmosphere_positive\n",
      "  16: atmosphere_negative\n",
      "  17: atmosphere_neutral\n"
     ]
    }
   ],
   "source": [
    "# Get predictions on test set\n",
    "predictions = trainer.predict(test_dataset)\n",
    "y_pred = (predictions.predictions > 0.5).astype(int)\n",
    "y_true = predictions.label_ids\n",
    "\n",
    "print(f\"RoBERTa ({SAMPLE_SIZE:,} Sample):\")\n",
    "print()\n",
    "print(f\"Training Accuracy: {trainer.evaluate(train_dataset)['eval_accuracy']:.4f}\")\n",
    "print(f\"Test Accuracy:     {trainer.evaluate(test_dataset)['eval_accuracy']:.4f}\")\n",
    "print()\n",
    "print(f\"F1 Score (macro):    {f1_score(y_true, y_pred, average='macro', zero_division=0):.4f}\")\n",
    "print(f\"F1 Score (weighted): {f1_score(y_true, y_pred, average='weighted', zero_division=0):.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, zero_division=0))\n",
    "print()\n",
    "print(\"\\nLabel Index Key:\")\n",
    "for i, label in enumerate(label_cols):\n",
    "    print(f\"  {i}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd1db9c-f9da-4d11-bb35-604a41e86f01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
